{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/release/docs/notebooks/integrations/working-with-openrouter.ipynb)&nbsp;&nbsp;\n",
        "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/notebooks/integrations/working-with-openrouter.ipynb)&nbsp;&nbsp;\n",
        "<a href=\"https://raw.githubusercontent.com/pixeltable/pixeltable/release/docs/notebooks/integrations/working-with-openrouter.ipynb\" download><img src=\"https://img.shields.io/badge/%E2%AC%87-Download%20Notebook-blue\" alt=\"Download Notebook\"></a>\n",
        "\n",
        "# Working with OpenRouter in Pixeltable\n",
        "\n",
        "Pixeltable's OpenRouter integration enables you to access multiple LLM providers through a unified API via OpenRouter.\n",
        "\n",
        "### Prerequisites\n",
        "- An OpenRouter account with an API key (https://openrouter.ai)\n",
        "\n",
        "### Important Notes\n",
        "\n",
        "- OpenRouter usage may incur costs based on the models you use and your usage volume.\n",
        "- Be mindful of sensitive data and consider security measures when integrating with external services.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First you'll need to install required libraries and enter your OpenRouter API key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if 'OPENROUTER_API_KEY' not in os.environ:\n",
        "    os.environ['OPENROUTER_API_KEY'] = getpass.getpass('Enter your OpenRouter API key:')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a Pixeltable directory to hold the tables for our demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "\n",
        "# Remove the 'openrouter_demo' directory and its contents, if it exists\n",
        "pxt.drop_dir('openrouter_demo', force=True)\n",
        "pxt.create_dir('openrouter_demo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chat Completions\n",
        "\n",
        "Create a Table: In Pixeltable, create a table with columns to represent your input data and the columns where you want to store the results from OpenRouter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pixeltable.functions import openrouter\n",
        "\n",
        "# Create a table in Pixeltable and add a computed column that calls OpenRouter\n",
        "t = pxt.create_table('openrouter_demo.chat', {'input': pxt.String})\n",
        "\n",
        "messages = [{'role': 'user', 'content': t.input}]\n",
        "\n",
        "t.add_computed_column(output=openrouter.chat_completions(\n",
        "    messages=messages,\n",
        "    model='anthropic/claude-3.5-sonnet',\n",
        "    model_kwargs={\n",
        "        # Optional dict with parameters compatible with the model\n",
        "        'max_tokens': 300,\n",
        "        'temperature': 0.7\n",
        "    }\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse the response into a new column\n",
        "t.add_computed_column(response=t.output.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start a conversation\n",
        "t.insert([\n",
        "    {'input': 'How many species of felids have been classified?'},\n",
        "    {'input': 'Can you make me a coffee?'}\n",
        "])\n",
        "t.select(t.input, t.response).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Different Models\n",
        "\n",
        "One of OpenRouter's key benefits is easy access to models from multiple providers. Let's create a table that compares responses from Anthropic Claude, OpenAI GPT-4, and Meta Llama.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table to compare different models\n",
        "compare_t = pxt.create_table('openrouter_demo.compare_models', {'prompt': pxt.String})\n",
        "\n",
        "messages = [{'role': 'user', 'content': compare_t.prompt}]\n",
        "\n",
        "# Add responses from different models\n",
        "compare_t.add_computed_column(\n",
        "    claude=openrouter.chat_completions(\n",
        "        messages=messages,\n",
        "        model='anthropic/claude-3.5-sonnet',\n",
        "        model_kwargs={'max_tokens': 150}\n",
        "    ).choices[0].message.content\n",
        ")\n",
        "\n",
        "compare_t.add_computed_column(\n",
        "    gpt4=openrouter.chat_completions(\n",
        "        messages=messages,\n",
        "        model='openai/gpt-4o-mini',\n",
        "        model_kwargs={'max_tokens': 150}\n",
        "    ).choices[0].message.content\n",
        ")\n",
        "\n",
        "compare_t.add_computed_column(\n",
        "    llama=openrouter.chat_completions(\n",
        "        messages=messages,\n",
        "        model='meta-llama/llama-3.1-8b-instruct',\n",
        "        model_kwargs={'max_tokens': 150}\n",
        "    ).choices[0].message.content\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert a prompt and compare responses\n",
        "compare_t.insert([{'prompt': 'Explain quantum entanglement in one sentence.'}])\n",
        "compare_t.select(compare_t.prompt, compare_t.claude, compare_t.gpt4, compare_t.llama).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Features: Provider Routing\n",
        "\n",
        "OpenRouter allows you to specify provider preferences for fallback behavior and cost optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table with provider routing\n",
        "routing_t = pxt.create_table('openrouter_demo.routing', {'input': pxt.String})\n",
        "\n",
        "messages = [{'role': 'user', 'content': routing_t.input}]\n",
        "routing_t.add_computed_column(\n",
        "    output=openrouter.chat_completions(\n",
        "        messages=messages,\n",
        "        model='anthropic/claude-3.5-sonnet',\n",
        "        model_kwargs={'max_tokens': 300},\n",
        "        # Specify provider preferences\n",
        "        provider={\n",
        "            'order': ['Anthropic', 'OpenAI'],  # Try Anthropic first, then OpenAI\n",
        "            'allow_fallbacks': True\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "routing_t.add_computed_column(response=routing_t.output.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "routing_t.insert([{'input': 'What are the primary colors?'}])\n",
        "routing_t.select(routing_t.input, routing_t.response).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Features: Context Window Optimization\n",
        "\n",
        "OpenRouter supports transforms like 'middle-out' to optimize handling of long contexts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table with transforms for long context optimization\n",
        "transform_t = pxt.create_table('openrouter_demo.transforms', {'long_context': pxt.String})\n",
        "\n",
        "messages = [{'role': 'user', 'content': transform_t.long_context}]\n",
        "transform_t.add_computed_column(\n",
        "    output=openrouter.chat_completions(\n",
        "        messages=messages,\n",
        "        model='openai/gpt-4o-mini',\n",
        "        model_kwargs={'max_tokens': 200},\n",
        "        # Apply middle-out transform for better long context handling\n",
        "        transforms=['middle-out']\n",
        "    )\n",
        ")\n",
        "\n",
        "transform_t.add_computed_column(response=transform_t.output.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example with longer context\n",
        "long_text = \"\"\"\n",
        "Artificial intelligence has transformed many industries. Machine learning algorithms \n",
        "can now detect patterns in data that humans might miss. Deep learning has revolutionized \n",
        "computer vision and natural language processing. The future of AI looks promising with \n",
        "developments in areas like reinforcement learning and generative models.\n",
        "\n",
        "Question: What are the main AI developments mentioned?\n",
        "\"\"\"\n",
        "\n",
        "transform_t.insert([{'long_context': long_text}])\n",
        "transform_t.select(transform_t.response).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learn More\n",
        "\n",
        "To learn more about advanced techniques like RAG operations in Pixeltable, check out the [RAG Operations in Pixeltable](https://pixeltable.readme.io/docs/rag-operations-in-pixeltable) tutorial.\n",
        "\n",
        "For more information about OpenRouter's features and available models, visit:\n",
        "- [OpenRouter Documentation](https://openrouter.ai/docs)\n",
        "- [Available Models](https://openrouter.ai/models)\n",
        "\n",
        "If you have any questions, don't hesitate to reach out.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pixeltable",
      "language": "python",
      "name": "pixeltable"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
