{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Chatbot with Memory\n",
        "\n",
        "Create conversations that remember context across messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable openai sentence-transformers spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "if 'OPENAI_API_KEY' not in os.environ:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "from pixeltable.functions import openai\n",
        "from pixeltable.functions.huggingface import sentence_transformer\n",
        "from pixeltable.iterators.string import StringSplitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Step 1: Store conversation history\n",
        "pxt.create_dir('chat', if_exists='ignore')\n",
        "history = pxt.create_table('chat.messages', {'role': pxt.String, 'content': pxt.String}, if_exists='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Create searchable memory\n",
        "memory = pxt.create_view('chat.memory', history, if_exists='ignore',\n",
        "    iterator=StringSplitter.create(text=history.content, separators='sentence'))\n",
        "memory.add_embedding_index('text', if_exists='ignore',\n",
        "    string_embed=sentence_transformer.using(model_id='intfloat/e5-large-v2'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Create context retrieval query\n",
        "@pxt.query\n",
        "def get_relevant_context(user_message: str):\n",
        "    sim = memory.text.similarity(user_message)\n",
        "    return memory.order_by(sim, asc=False).select(memory.text, sim=sim).limit(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Create chat table with LLM\n",
        "chat = pxt.create_table('chat.conversation', {'user_message': pxt.String}, if_exists='ignore')\n",
        "chat.add_computed_column(context=get_relevant_context(chat.user_message), if_exists='ignore')\n",
        "\n",
        "@pxt.udf\n",
        "def build_prompt(context: list[dict], message: str) -> str:\n",
        "    relevant = '\\n'.join(item['text'] for item in context if item['sim'] > 0.3)\n",
        "    return f\"Context:\\n{relevant}\\n\\nUser: {message}\" if relevant else message\n",
        "\n",
        "chat.add_computed_column(prompt=build_prompt(chat.context, chat.user_message), if_exists='ignore')\n",
        "chat.add_computed_column(if_exists='ignore',\n",
        "    response=openai.chat_completions(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=[{'role': 'user', 'content': chat.prompt}]\n",
        "    ).choices[0].message.content\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Have a conversation\n",
        "history.insert([{'role': 'user', 'content': 'My favorite color is blue'}])\n",
        "chat.insert([{'user_message': 'What color do I like?'}])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View response\n",
        "print(chat.select(chat.response).tail(1)['response'][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What's Happening:**\n",
        "- Conversation history stored in table\n",
        "- Memory view splits messages into searchable sentences\n",
        "- Semantic search finds relevant context\n",
        "- LLM gets context + current message\n",
        "\n",
        "**Variation:** Add conversation to history after each response:\n",
        "```python\n",
        "# After getting response\n",
        "history.insert([\n",
        "    {'role': 'user', 'content': user_message},\n",
        "    {'role': 'assistant', 'content': response}\n",
        "])\n",
        "```\n",
        "\n",
        "**Next:** `answer-questions-from-docs.ipynb` â€¢ `let-ai-search-web-for-answers.ipynb`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
