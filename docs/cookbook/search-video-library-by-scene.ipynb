{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Search Video Library by Scene\n",
        "\n",
        "Find specific moments in your videos using text descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU pixeltable sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pixeltable as pxt\n",
        "from pixeltable.functions.huggingface import clip\n",
        "from pixeltable.iterators import FrameIterator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Store videos\n",
        "pxt.create_dir('videos', if_exists='ignore')\n",
        "vids = pxt.create_table('videos.library', {'video': pxt.Video}, if_exists='ignore')\n",
        "vids.insert([{'video': 'https://github.com/pixeltable/pixeltable/raw/release/docs/resources/bangkok.mp4'}])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pxt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Extract frames and create CLIP index\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mpxt\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_view(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos.frames\u001b[39m\u001b[38;5;124m'\u001b[39m, vids, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     iterator\u001b[38;5;241m=\u001b[39mFrameIterator\u001b[38;5;241m.\u001b[39mcreate(video\u001b[38;5;241m=\u001b[39mvids\u001b[38;5;241m.\u001b[39mvideo, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m frames\u001b[38;5;241m.\u001b[39madd_embedding_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mclip\u001b[38;5;241m.\u001b[39musing(model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai/clip-vit-base-patch32\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pxt' is not defined"
          ]
        }
      ],
      "source": [
        "# Step 2: Extract frames and create CLIP index\n",
        "frames = pxt.create_view('videos.frames', vids, if_exists='ignore',\n",
        "    iterator=FrameIterator.create(video=vids.video, fps=1))\n",
        "frames.add_embedding_index('frame', if_exists='ignore',\n",
        "    embedding=clip.using(model_id='openai/clip-vit-base-patch32'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Search for frames\n",
        "sim = frames.frame.similarity(\"people walking on street\")\n",
        "results = frames.order_by(sim, asc=False).select(frames.frame, frames.pos, sim=sim).limit(5).collect()\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What's Happening:**\n",
        "- Video → frames extracted at 1 FPS\n",
        "- Frames → CLIP embeddings (automatic)\n",
        "- Text query → similar frames (cross-modal search)\n",
        "- Results show frame image + timestamp (`pos`)\n",
        "\n",
        "**Variation:** Search by image instead of text:\n",
        "```python\n",
        "sim = frames.frame.similarity(reference_image_url)\n",
        "```\n",
        "\n",
        "**Next:** `create-video-highlight-reel.ipynb` • `detect-products-in-video-ads.ipynb`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pixeltable",
      "language": "python",
      "name": "pixeltable"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
